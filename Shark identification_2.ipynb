{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNByf7Y3HDqHNY3JCznihKI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HatemMoushir/Shark-identification-1/blob/main/Shark%20identification_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yF77CVlhTJ1-"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install # âœ… ØªØ«Ø¨ÙŠØª Ù…ÙƒØªØ¨Ø© Ø¨Ø¯ÙŠÙ„Ø©\n",
        "!pip install -q simple_image_download\n",
        "\n",
        "# âœ… Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª\n",
        "import os\n",
        "from simple_image_download import simple_image_download as simp\n",
        "\n",
        "# âœ… Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ø¬Ù„Ø¯ Ø§Ù„ØµÙˆØ±\n",
        "save_dir = \"shark_fins\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# âœ… Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£Ù†ÙˆØ§Ø¹\n",
        "shark_species = [\n",
        "    (\"Scalloped hammerhead\", \"Sphyrna lewini\"),\n",
        "    (\"Great hammerhead\", \"Sphyrna mokarran\"),\n",
        "    (\"Oceanic whitetip shark\", \"Carcharhinus longimanus\"),\n",
        "    (\"Tiger shark\", \"Galeocerdo cuvier\"),\n",
        "    (\"Silky shark\", \"Carcharhinus falciformis\"),\n",
        "    (\"Blacktip shark\", \"Carcharhinus limbatus\"),\n",
        "    (\"Dusky shark\", \"Carcharhinus obscurus\"),\n",
        "    (\"Grey reef shark\", \"Carcharhinus amblyrhynchos\"),\n",
        "    (\"Thresher shark\", \"Alopias vulpinus\"),\n",
        "    (\"Shortfin mako\", \"Isurus oxyrinchus\")\n",
        "]\n",
        "\n",
        "# âœ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±\n",
        "response = simp.simple_image_download\n",
        "\n",
        "for common, scientific in shark_species:\n",
        "    folder = os.path.join(save_dir, common.replace(\" \", \"_\"))\n",
        "\n",
        "    # Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ø´Ø§Ø¦Ø¹ ÙˆØ§Ù„Ø¹Ù„Ù…ÙŠ\n",
        "    os.makedirs(os.path.join(folder, \"common_name\"), exist_ok=True)\n",
        "    os.makedirs(os.path.join(folder, \"scientific_name\"), exist_ok=True)\n",
        "\n",
        "    print(f\"â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ± Ù„Ù€ {common}...\")\n",
        "\n",
        "    # ØªØ­Ù…ÙŠÙ„ ØµÙˆØ± Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ø´Ø§Ø¦Ø¹\n",
        "    response().download(f\"{common} dorsal fin\", 250, extensions=['.jpg', '.jpeg', '.png'])\n",
        "    os.system(f\"mv simple_images/{common.replace(' ', '_')}/* '{folder}/common_name/'\")\n",
        "\n",
        "    # ØªØ­Ù…ÙŠÙ„ ØµÙˆØ± Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ø¹Ù„Ù…ÙŠ\n",
        "    response().download(f\"{scientific} dorsal fin\", 250, extensions=['.jpg', '.jpeg', '.png'])\n",
        "    os.system(f\"mv simple_images/{scientific.replace(' ', '_')}/* '{folder}/scientific_name/'\")\n",
        "\n",
        "print(\"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØµÙˆØ±.\")\n",
        "\n",
        "from icrawler.builtin import GoogleImageCrawler\n",
        "import os\n",
        "\n",
        "# Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù‚Ø±ÙˆØ´ Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ© Ù…Ø¹ ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¨Ø­Ø«\n",
        "shark_types = {\n",
        "    \"great_white\": \"great white shark dorsal fin\",\n",
        "    \"tiger\": \"tiger shark dorsal fin\",\n",
        "    \"bull\": \"bull shark dorsal fin\"\n",
        "}\n",
        "\n",
        "# Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù„ÙƒÙ„ Ù†ÙˆØ¹\n",
        "num_images = 100\n",
        "\n",
        "# Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù„Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±\n",
        "base_dir = \"shark_fins_dataset\"\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±\n",
        "for label, query in shark_types.items():\n",
        "    save_dir = os.path.join(base_dir, label)\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    print(f\"\\nğŸ” Downloading up to {num_images} images for '{label}' ({query})...\")\n",
        "\n",
        "    crawler = GoogleImageCrawler(storage={'root_dir': save_dir})\n",
        "    crawler.crawl(keyword=query, max_num=num_images, file_idx_offset=0)\n",
        "\n",
        "    # Ø¹Ø¯Ù‘ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø© ÙØ¹Ù„ÙŠÙ‹Ø§\n",
        "    downloaded = len([f for f in os.listdir(save_dir) if os.path.isfile(os.path.join(save_dir, f))])\n",
        "    print(f\"âœ… Downloaded {downloaded} image(s) for '{label}'\")\n",
        "\n",
        "print(\"\\nğŸ¯ All downloads completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.make_archive(\"shark_dataset\", 'zip', \"shark_dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wjLHTZa_UyA3",
        "outputId": "10dbcefc-30f8-4821-e634-2d16c5ae420b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/shark_dataset.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"shark_dataset.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Fm3BfaQfU1_B",
        "outputId": "d7c9bd93-dbf9-4c3f-f6f8-aa8d0ec11393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a9b1bf9a-7904-4fa6-8b4e-294b17197c5f\", \"shark_dataset.zip\", 393620248)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import glob\n",
        "\n",
        "def is_valid_image(path, min_size=(100, 100)):\n",
        "    try:\n",
        "        img = Image.open(path)\n",
        "        img.verify()  # ØªØ£ÙƒØ¯ Ø£Ù† Ø§Ù„Ù…Ù„Ù ØµÙˆØ±Ø© Ø­Ù‚ÙŠÙ‚ÙŠØ©\n",
        "        img = Image.open(path)  # Ù†Ø­ØªØ§Ø¬ Ù†Ø¹ÙŠØ¯ ÙØªØ­Ù‡Ø§ Ø¨Ø¹Ø¯ verify\n",
        "        return img.size[0] >= min_size[0] and img.size[1] >= min_size[1]\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "# Ù†Ø­Ø°Ù Ø§Ù„ØµÙˆØ± ØºÙŠØ± Ø§Ù„ØµØ§Ù„Ø­Ø©\n",
        "def filter_invalid_images(root_dir):\n",
        "    for class_dir in os.listdir(root_dir):\n",
        "        class_path = os.path.join(root_dir, class_dir)\n",
        "        for img_path in glob.glob(f\"{class_path}/*\"):\n",
        "            if not is_valid_image(img_path):\n",
        "                print(f\"ğŸ—‘ï¸ Removing invalid: {img_path}\")\n",
        "                os.remove(img_path)\n",
        "\n",
        "# ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙÙ„ØªØ±Ø©\n",
        "filter_invalid_images(dataset_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HRi8RhAhCOH",
        "outputId": "dcdcb41a-7b66-4d49-ff9f-6e9f35d0851b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ—‘ï¸ Removing invalid: ./shark_dataset/Blacktip_Shark/000024.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def resize_all_images(root_dir, size=(224, 224)):\n",
        "    for class_dir in os.listdir(root_dir):\n",
        "        class_path = os.path.join(root_dir, class_dir)\n",
        "        for img_path in glob.glob(f\"{class_path}/*\"):\n",
        "            try:\n",
        "                img = Image.open(img_path)\n",
        "                img = img.convert(\"RGB\")  # ØªØ£ÙƒØ¯ Ù…Ù† 3 Ù‚Ù†ÙˆØ§Øª\n",
        "                img = img.resize(size)\n",
        "                img.save(img_path)\n",
        "            except Exception as e:\n",
        "                print(f\"âŒ Failed resizing {img_path}: {e}\")\n",
        "\n",
        "# ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„\n",
        "resize_all_images(dataset_dir)"
      ],
      "metadata": {
        "id": "OMa9DUlbhs_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "def split_dataset(input_dir, output_dir, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):\n",
        "    random.seed(42)  # Ù„ØªÙƒØ±Ø§Ø± Ù†ÙØ³ Ø§Ù„Ù†ØªØ§Ø¦Ø¬\n",
        "\n",
        "    for class_name in os.listdir(input_dir):\n",
        "        class_path = os.path.join(input_dir, class_name)\n",
        "        if not os.path.isdir(class_path):\n",
        "            continue\n",
        "\n",
        "        images = os.listdir(class_path)\n",
        "        random.shuffle(images)\n",
        "\n",
        "        total = len(images)\n",
        "        train_cut = int(train_ratio * total)\n",
        "        val_cut = int((train_ratio + val_ratio) * total)\n",
        "\n",
        "        splits = {\n",
        "            \"train\": images[:train_cut],\n",
        "            \"val\": images[train_cut:val_cut],\n",
        "            \"test\": images[val_cut:]\n",
        "        }\n",
        "\n",
        "        for split_name, split_images in splits.items():\n",
        "            split_class_dir = os.path.join(output_dir, split_name, class_name)\n",
        "            os.makedirs(split_class_dir, exist_ok=True)\n",
        "\n",
        "            for img in split_images:\n",
        "                src = os.path.join(class_path, img)\n",
        "                dst = os.path.join(split_class_dir, img)\n",
        "                shutil.copy2(src, dst)\n",
        "\n",
        "# ØªÙ†ÙÙŠØ° Ø§Ù„ØªÙ‚Ø³ÙŠÙ…\n",
        "split_dataset(dataset_dir, \"/content/split_dataset\")"
      ],
      "metadata": {
        "id": "hcfbpxFZiU0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "\n",
        "# Ù†Ø¶Ø¨Ø· Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ±Ø© Ø¨Ù…Ø§ ÙŠØªÙ†Ø§Ø³Ø¨ Ù…Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Ù…Ø«Ù„Ø§Ù‹ 224x224)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])"
      ],
      "metadata": {
        "id": "2efcUskPifge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª\n",
        "train_path = \"/content/split_dataset/train\"\n",
        "val_path = \"/content/split_dataset/val\"\n",
        "test_path = \"/content/split_dataset/test\"\n",
        "\n",
        "# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
        "train_dataset = datasets.ImageFolder(train_path, transform=transform)\n",
        "val_dataset = datasets.ImageFolder(val_path, transform=transform)\n",
        "test_dataset = datasets.ImageFolder(test_path, transform=transform)\n",
        "\n",
        "# DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Ø·Ø¨Ø§Ø¹Ø© Ø¹Ø¯Ø¯ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª\n",
        "print(f\"ğŸ§  Ø¹Ø¯Ø¯ ØµÙˆØ± Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {len(train_dataset)}\")\n",
        "print(f\"ğŸ“Š Ø¹Ø¯Ø¯ ØµÙˆØ± Ø§Ù„ØªØ­Ù‚Ù‚: {len(val_dataset)}\")\n",
        "print(f\"ğŸ” Ø¹Ø¯Ø¯ ØµÙˆØ± Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: {len(test_dataset)}\")\n",
        "\n",
        "# Ø¹Ø±Ø¶ Ø§Ù„ÙØ¦Ø§Øª\n",
        "print(f\"ğŸ“¦ Ø§Ù„ÙØ¦Ø§Øª: {train_dataset.classes}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79KXlTOZi5pe",
        "outputId": "476d7d75-589c-4c61-c210-98679463e1ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  Ø¹Ø¯Ø¯ ØµÙˆØ± Ø§Ù„ØªØ¯Ø±ÙŠØ¨: 1134\n",
            "ğŸ“Š Ø¹Ø¯Ø¯ ØµÙˆØ± Ø§Ù„ØªØ­Ù‚Ù‚: 244\n",
            "ğŸ” Ø¹Ø¯Ø¯ ØµÙˆØ± Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: 246\n",
            "ğŸ“¦ Ø§Ù„ÙØ¦Ø§Øª: ['Blacktip_Shark', 'Great_White_Shark', 'Hammerhead_Shark', 'Silky_Shark', 'Tiger_Shark', 'Whale_Shark', 'Whitetip_Shark']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CNNModel, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "\n",
        "        self.fc1 = nn.Linear(64 * 28 * 28, 256)\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # [B, 16, 112, 112]\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # [B, 32, 56, 56]\n",
        "        x = self.pool(F.relu(self.conv3(x)))  # [B, 64, 28, 28]\n",
        "        x = x.view(-1, 64 * 28 * 28)\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "p0FYLLPNjTrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ØªØ­Ø¯ÙŠØ¯ Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª Ù…Ù† Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨\n",
        "num_classes = len(train_dataset.classes)\n",
        "\n",
        "# ØªØ­Ù…ÙŠÙ„ Ø¹Ù„Ù‰ CUDA Ø£Ùˆ CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬\n",
        "model = CNNModel(num_classes).to(device)\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POcbQJkMjbfo",
        "outputId": "445f44db-b714-40bc-dd15-893395870e70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNNModel(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (fc1): Linear(in_features=50176, out_features=256, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=7, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Ø¯Ø§Ù„Ø© Ø§Ù„ÙÙ‚Ø¯: ØªØµÙ†ÙŠÙ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª => CrossEntropyLoss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Ø§Ù„Ù…ÙØ­Ø³Ù‘Ù†: Adam Ù…Ø¹ learning rate\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "AP5SfwfJjplq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    model.train()\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # ØªØµÙÙŠØ± Ø§Ù„Ù€ gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Ø§Ù„ØªÙ†Ø¨Ø¤\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Ø­Ø³Ø§Ø¨ Ø§Ù„ÙÙ‚Ø¯\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Ø§Ù„ØªØ¯Ø±Ø¬ Ø§Ù„Ø¹ÙƒØ³ÙŠ ÙˆØ§Ù„ØªØ­Ø¯ÙŠØ«\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "print(\"âœ… Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø®Ù„Øµ.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgs2Pcy6jw3n",
        "outputId": "2ed5d525-8643-430f-d0b9-263aecf48177"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5] - Loss: 1.9652\n",
            "Epoch [2/5] - Loss: 1.8655\n",
            "Epoch [3/5] - Loss: 1.8048\n",
            "Epoch [4/5] - Loss: 1.7774\n",
            "Epoch [5/5] - Loss: 1.7443\n",
            "âœ… Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø®Ù„Øµ.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, val_loader):\n",
        "    model.eval()  # Ù†Ù…Ø· Ø§Ù„ØªÙ‚ÙŠÙŠÙ…\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'âœ… Accuracy on validation set: {accuracy:.2f}%')\n",
        "\n",
        "# Ù†ÙØ° Ø§Ù„ØªÙ‚ÙŠÙŠÙ…\n",
        "evaluate_model(model, val_loader)"
      ],
      "metadata": {
        "id": "W4UCL3OzlPPR",
        "outputId": "edee92cd-84c6-44fb-e42b-66b81860153f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Accuracy on validation set: 25.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "!pip install torch torchvision\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# âœ… Ø§Ø³ØªØ®Ø¯Ø§Ù… GPU Ù„Ùˆ Ù…ØªØ§Ø­\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# âœ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_dataset = datasets.ImageFolder(\"shark_data_split/train\", transform=transform)\n",
        "test_dataset = datasets.ImageFolder(\"shark_data_split/test\", transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# âœ… ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ ResNet18\n",
        "model = models.resnet18(pretrained=True)\n",
        "num_classes = len(train_dataset.classes)\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "model = model.to(device)\n",
        "\n",
        "# âœ… Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# âœ… ØªØ¯Ø±ÙŠØ¨ Ø³Ø±ÙŠØ¹ (5 epochs ÙÙ‚Ø· ÙƒØ¨Ø¯Ø§ÙŠØ©)\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    acc = correct / total * 100\n",
        "    print(f\"ğŸ“¦ Epoch [{epoch+1}/{epochs}] - Loss: {total_loss:.4f} - Accuracy: {acc:.2f}%\")\n",
        "\n",
        "# âœ… Ø§Ø®ØªØ¨Ø§Ø± Ø³Ø±ÙŠØ¹\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "test_acc = correct / total * 100\n",
        "print(f\"\\nğŸ§ª Test Accuracy: {test_acc:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1QEWvBCW6SP",
        "outputId": "2acd1d5d-9d71-490f-80ee-75e1b6569f24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44.7M/44.7M [00:00<00:00, 134MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¦ Epoch [1/5] - Loss: 9.0012 - Accuracy: 48.55%\n",
            "ğŸ“¦ Epoch [2/5] - Loss: 3.1816 - Accuracy: 86.96%\n",
            "ğŸ“¦ Epoch [3/5] - Loss: 2.1911 - Accuracy: 93.48%\n",
            "ğŸ“¦ Epoch [4/5] - Loss: 1.5495 - Accuracy: 92.75%\n",
            "ğŸ“¦ Epoch [5/5] - Loss: 1.3707 - Accuracy: 92.75%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1043: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ§ª Test Accuracy: 59.46%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…ÙƒØªØ¨Ø©\n",
        "!pip install icrawler\n",
        "\n",
        "# âœ… Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø£Ø¯ÙˆØ§Øª\n",
        "import os\n",
        "from icrawler.builtin import BingImageCrawler  # Ù…Ù…ÙƒÙ† Ù†Ø¨Ø¯Ù‘Ù„ GoogleImageCrawler Ù„Ùˆ Ø£Ø±Ø¯Øª\n",
        "\n",
        "# âœ… Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù‚Ø±ÙˆØ´ Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©\n",
        "shark_types = {\n",
        "    \"Blacktip_Shark\": \"Blacktip shark fin above water\",\n",
        "    \"Whitetip_Shark\": \"Oceanic whitetip shark dorsal fin above water\",\n",
        "    \"Hammerhead_Shark\": \"Hammerhead shark fin above water\",\n",
        "    \"Whale_Shark\": \"Whale shark fin above water\",\n",
        "    \"Silky_Shark\": \"Silky shark fin above water\",\n",
        "    \"Tiger_Shark\": \"Tiger shark fin above water\",\n",
        "    \"Great_White_Shark\": \"Great white shark fin above water\"\n",
        "}\n",
        "\n",
        "# âœ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
        "dataset_dir = \"./shark_dataset\"\n",
        "os.makedirs(dataset_dir, exist_ok=True)\n",
        "\n",
        "# âœ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±\n",
        "for folder_name, query in shark_types.items():\n",
        "    save_dir = os.path.join(dataset_dir, folder_name)\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    print(f\"\\nğŸ”½ Now downloading: {folder_name} ...\")\n",
        "    crawler = BingImageCrawler(storage={\"root_dir\": save_dir})\n",
        "    crawler.crawl(keyword=query, max_num=500)"
      ],
      "metadata": {
        "id": "AAbT7P7fcK45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "def clean_corrupt_images(dataset_path):\n",
        "    removed = 0\n",
        "    for root, dirs, files in os.walk(dataset_path):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            try:\n",
        "                with Image.open(file_path) as img:\n",
        "                    img.verify()  # ØªØ­Ù‚Ù‚ ÙÙ‚Ø· Ø¯ÙˆÙ† ÙØªØ­ ÙƒØ§Ù…Ù„\n",
        "            except (IOError, SyntaxError):\n",
        "                print(f\"âŒ Removing corrupt image: {file_path}\")\n",
        "                os.remove(file_path)\n",
        "                removed += 1\n",
        "    print(f\"\\nâœ… Cleaning done. Removed {removed} corrupt images.\")\n",
        "\n",
        "clean_corrupt_images(\"shark_fins_dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kX3SRxdvYqL2",
        "outputId": "bf5b4534-c806-4991-d188-8c90285e0e85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âŒ Removing corrupt image: shark_fins_dataset/tiger/000005.jpg\n",
            "âŒ Removing corrupt image: shark_fins_dataset/tiger/000012.jpg\n",
            "âŒ Removing corrupt image: shark_fins_dataset/great_white/000030.jpg\n",
            "âŒ Removing corrupt image: shark_fins_dataset/great_white/000053.jpg\n",
            "\n",
            "âœ… Cleaning done. Removed 4 corrupt images.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "def split_dataset(source_dir, train_ratio=0.8):\n",
        "    random.seed(42)\n",
        "    target_base = \"shark_data_split\"\n",
        "    for class_name in os.listdir(source_dir):\n",
        "        class_path = os.path.join(source_dir, class_name)\n",
        "        if not os.path.isdir(class_path):\n",
        "            continue\n",
        "\n",
        "        images = os.listdir(class_path)\n",
        "        random.shuffle(images)\n",
        "        split_idx = int(len(images) * train_ratio)\n",
        "\n",
        "        train_dir = os.path.join(target_base, \"train\", class_name)\n",
        "        test_dir = os.path.join(target_base, \"test\", class_name)\n",
        "        os.makedirs(train_dir, exist_ok=True)\n",
        "        os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "        for i, img in enumerate(images):\n",
        "            src_path = os.path.join(class_path, img)\n",
        "            dst_dir = train_dir if i < split_idx else test_dir\n",
        "            shutil.copy2(src_path, os.path.join(dst_dir, img))\n",
        "\n",
        "    print(\"\\nâœ… Dataset split complete!\")\n",
        "\n",
        "split_dataset(\"shark_fins_dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1da_nnVY47Y",
        "outputId": "9dd139de-0be3-4501-b5b0-b799b7720f32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Dataset split complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ù„ØµÙˆØ±\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
        "train_data = datasets.ImageFolder(\"shark_data_split/train\", transform=transform)\n",
        "test_data = datasets.ImageFolder(\"shark_data_split/test\", transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=16, shuffle=False)\n",
        "\n",
        "print(f\"âœ… Loaded {len(train_data)} training images and {len(test_data)} testing images.\")\n",
        "print(f\"Classes: {train_data.classes}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcybxiEXY_UM",
        "outputId": "05121454-7b8c-40a2-e0b0-750b4d44fe47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Loaded 138 training images and 37 testing images.\n",
            "Classes: ['bull', 'great_white', 'tiger']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "for root, dirs, files in os.walk(\"shark_data_split\"):\n",
        "    level = root.replace(\"shark_data_split\", \"\").count(os.sep)\n",
        "    indent = \" \" * 2 * level\n",
        "    print(f\"{indent}{os.path.basename(root)}/\")\n",
        "    for f in files[:3]:  # Ø¹Ø±Ø¶ Ø£ÙˆÙ„ 3 ØµÙˆØ± ÙÙ‚Ø· Ù…Ù† ÙƒÙ„ Ù…Ø¬Ù„Ø¯\n",
        "        print(f\"{indent}  {f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooB4pesxZRqy",
        "outputId": "e140e0c2-aeef-490c-9e78-f3d7b8a8ff5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shark_data_split/\n",
            "  train/\n",
            "    tiger/\n",
            "      000051.jpg\n",
            "      000056.jpg\n",
            "      000052.jpg\n",
            "    great_white/\n",
            "      000009.jpg\n",
            "      000051.jpg\n",
            "      000056.jpg\n",
            "    bull/\n",
            "      000009.jpg\n",
            "      000051.jpg\n",
            "      000048.jpg\n",
            "  test/\n",
            "    tiger/\n",
            "      000048.jpg\n",
            "      000035.jpg\n",
            "      000014.jpg\n",
            "    great_white/\n",
            "      000048.png\n",
            "      000052.jpg\n",
            "      000004.jpg\n",
            "    bull/\n",
            "      000014.png\n",
            "      000037.jpg\n",
            "      000038.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8202c367"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Define the base directory for the downloaded images and the new split dataset directory\n",
        "base_download_dir = \"shark_fins_dataset\"\n",
        "base_split_dir = \"shark_data_split\"\n",
        "\n",
        "# Define the train and test split ratio\n",
        "train_ratio = 0.8\n",
        "test_ratio = 1.0 - train_ratio\n",
        "\n",
        "# Create the base split directory\n",
        "os.makedirs(base_split_dir, exist_ok=True)\n",
        "\n",
        "# Iterate through the downloaded shark types (folders)\n",
        "for shark_type in os.listdir(base_download_dir):\n",
        "    shark_type_dir = os.path.join(base_download_dir, shark_type)\n",
        "\n",
        "    # Ensure it's a directory\n",
        "    if os.path.isdir(shark_type_dir):\n",
        "        # Create corresponding train and test directories in the split dataset directory\n",
        "        train_dir = os.path.join(base_split_dir, \"train\", shark_type)\n",
        "        test_dir = os.path.join(base_split_dir, \"test\", shark_type)\n",
        "        os.makedirs(train_dir, exist_ok=True)\n",
        "        os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "        # Get the list of image files and shuffle it\n",
        "        images = [f for f in os.listdir(shark_type_dir) if os.path.isfile(os.path.join(shark_type_dir, f))]\n",
        "        random.shuffle(images)\n",
        "\n",
        "        # Calculate the number of images for training and testing\n",
        "        num_train = int(len(images) * train_ratio)\n",
        "        # num_test = len(images) - num_train # No need to calculate num_test explicitly\n",
        "\n",
        "        # Split the images and copy them to the new directories\n",
        "        train_images = images[:num_train]\n",
        "        test_images = images[num_train:]\n",
        "\n",
        "        print(f\"Splitting {shark_type}: {len(train_images)} for training, {len(test_images)} for testing\")\n",
        "\n",
        "        for img in train_images:\n",
        "            src = os.path.join(shark_type_dir, img)\n",
        "            dst = os.path.join(train_dir, img)\n",
        "            shutil.copyfile(src, dst)\n",
        "\n",
        "        for img in test_images:\n",
        "            src = os.path.join(shark_type_dir, img)\n",
        "            dst = os.path.join(test_dir, img)\n",
        "            shutil.copyfile(src, dst)\n",
        "\n",
        "print(\"\\nData split completed.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}