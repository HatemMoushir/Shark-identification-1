{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HatemMoushir/Shark-identification-1/blob/main/Shark%20identification_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgaBTwlUOS9a",
        "outputId": "eea3a817-f5a1-433b-a77c-e76b6eab0779"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCeXlEKfOika",
        "outputId": "29a53fda-da03-42a1-a5a0-2a14fbb3a223"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['shark_fins_raw', 'sharks_raw.zip']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "path = \"/content/drive/MyDrive/Shark_project\"\n",
        "files = os.listdir(path)\n",
        "print(files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8-HE0VlS9QK",
        "outputId": "46db2b64-cb19-4823-d7e6-2f5d2263c76e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/296.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”\u001b[0m \u001b[32m286.7/296.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m296.7/296.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q imagehash Pillow pytesseract\n",
        "\n",
        "import os\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "import imagehash\n",
        "import pytesseract\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "base_path = \"/content/drive/MyDrive/Shark_project\"\n",
        "min_size = (100, 100)\n",
        "hash_dict = defaultdict(list)\n",
        "duplicates = defaultdict(list)\n",
        "bad_images = []\n",
        "small_images = []\n",
        "images_with_text = []\n",
        "\n",
        "def display_images(image_paths, title):\n",
        "    print(f\"\\nğŸ“¸ {title} - Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ±: {len(image_paths)}\\n\")\n",
        "    for path in image_paths[:10]:\n",
        "        try:\n",
        "            img = Image.open(path).convert(\"RGB\")\n",
        "            plt.imshow(img)\n",
        "            plt.title(os.path.basename(path))\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¹Ø±Ø¶: {path}\", e)\n",
        "\n",
        "def has_text(img):\n",
        "    text = pytesseract.image_to_string(img)\n",
        "    return bool(text.strip())\n",
        "\n",
        "for root, dirs, files in os.walk(base_path):\n",
        "    for img_name in files:\n",
        "        img_path = os.path.join(root, img_name)\n",
        "        if not os.path.isfile(img_path):\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            img = Image.open(img_path)\n",
        "            img.verify()\n",
        "            img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "            if img.size[0] < min_size[0] or img.size[1] < min_size[1]:\n",
        "                small_images.append(img_path)\n",
        "\n",
        "            hash_val = imagehash.phash(img)\n",
        "            hash_dict[str(hash_val)].append(img_path)\n",
        "\n",
        "            if has_text(img):\n",
        "                images_with_text.append(img_path)\n",
        "\n",
        "        except (UnidentifiedImageError, OSError) as e:\n",
        "            bad_images.append(img_path)\n",
        "\n",
        "for h, paths in hash_dict.items():\n",
        "    if len(paths) > 1:\n",
        "        duplicates[h] = paths\n",
        "\n",
        "if small_images:\n",
        "    display_images(small_images, \"ØµÙˆØ± ØµØºÙŠØ±Ø© Ø§Ù„Ø­Ø¬Ù…\")\n",
        "\n",
        "if images_with_text:\n",
        "    display_images(images_with_text, \"ØµÙˆØ± ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙƒØªØ§Ø¨Ø© / Ø¹Ù„Ø§Ù…Ø© Ù…Ø§Ø¦ÙŠØ©\")\n",
        "\n",
        "if duplicates:\n",
        "    print(f\"\\nğŸ” Ù…Ø¬Ù…ÙˆØ¹Ø§Øª ØµÙˆØ± Ù…ÙƒØ±Ø±Ø© Ø¨ØµØ±ÙŠÙ‹Ø§: {len(duplicates)}\\n\")\n",
        "    for i, (h, paths) in enumerate(duplicates.items()):\n",
        "        display_images(paths, f\"ØµÙˆØ± Ù…ÙƒØ±Ø±Ø© - Ù…Ø¬Ù…ÙˆØ¹Ø© {i+1}\")\n",
        "\n",
        "if bad_images:\n",
        "    display_images(bad_images, \"ØµÙˆØ± ØªØ§Ù„ÙØ©\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = ImageFolder(\"/content/Shark_project_split/train\")\n",
        "print(dataset.classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmLOJXpwTYGY",
        "outputId": "34850e85-621f-4c8d-820d-9b562381fa70"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Blacktip_Shark', 'Bull_Shark', 'Great_White_Shark', 'Hammerhead_Shark', 'Mako_Shark', 'Tiger_Shark', 'Whale_Shark', 'Whitetip_Shark']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QWoMu-_VT3DD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGHa3MnN0PEO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgsPZyT8PVDm"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©\n",
        "!pip install -q imagehash Pillow\n",
        "\n",
        "import os\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "import imagehash\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ ÙÙŠ Google Drive\n",
        "#base_path = \"/content/drive/MyDrive/Shark_project\"\n",
        "base_path = \"/content/Shark_project\"\n",
        "\n",
        "# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø¹Ø§Ù…Ø©\n",
        "min_size = (100, 100)\n",
        "hash_dict = defaultdict(list)\n",
        "duplicates = defaultdict(list)\n",
        "bad_images = []\n",
        "small_images = []\n",
        "\n",
        "# Ø¯Ø§Ù„Ø© Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±\n",
        "def display_images(image_paths, title):\n",
        "    print(f\"\\nğŸ“¸ {title} - Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ±: {len(image_paths)}\\n\")\n",
        "    for i, path in enumerate(image_paths[:10]):  # Ù†Ø¹Ø±Ø¶ ÙÙ‚Ø· Ø£ÙˆÙ„ 10 ØµÙˆØ±\n",
        "        try:\n",
        "            img = Image.open(path).convert(\"RGB\")\n",
        "            plt.imshow(img)\n",
        "            plt.title(f\"{os.path.basename(path)}\")\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¹Ø±Ø¶: {path}\", e)\n",
        "\n",
        "# -------------------------------\n",
        "# ÙØ­Øµ Ø´Ø§Ù…Ù„ Ù„ÙƒÙ„ Ø§Ù„ØµÙˆØ± Ø¨Ø´ÙƒÙ„ Recursive\n",
        "# -------------------------------\n",
        "for root, dirs, files in os.walk(base_path):\n",
        "    for img_name in files:\n",
        "        img_path = os.path.join(root, img_name)\n",
        "\n",
        "        if not os.path.isfile(img_path):\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            img = Image.open(img_path)\n",
        "            img.verify()  # ÙØ­Øµ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ØªØ§Ù„ÙØ©\n",
        "            img = Image.open(img_path).convert(\"RGB\")  # Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ÙØªØ­ Ù„ØªØ­Ù„ÙŠÙ„Ù‡Ø§\n",
        "\n",
        "            # ÙØ­Øµ Ø§Ù„Ø­Ø¬Ù…\n",
        "            if img.size[0] < min_size[0] or img.size[1] < min_size[1]:\n",
        "                small_images.append(img_path)\n",
        "\n",
        "            # Ø­Ø³Ø§Ø¨ hash\n",
        "            hash_val = imagehash.phash(img)\n",
        "            hash_dict[str(hash_val)].append(img_path)\n",
        "\n",
        "        except (UnidentifiedImageError, OSError) as e:\n",
        "            bad_images.append(img_path)\n",
        "\n",
        "# -------------------------------\n",
        "# Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…ÙƒØ±Ø±Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ phash\n",
        "# -------------------------------\n",
        "for h, paths in hash_dict.items():\n",
        "    if len(paths) > 1:\n",
        "        duplicates[h] = paths\n",
        "\n",
        "# -------------------------------\n",
        "# Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬\n",
        "# -------------------------------\n",
        "\n",
        "# Ø§Ù„ØµÙˆØ± ØµØºÙŠØ±Ø© Ø§Ù„Ø­Ø¬Ù…\n",
        "if small_images:\n",
        "    display_images(small_images, \"ØµÙˆØ± ØµØºÙŠØ±Ø© Ø§Ù„Ø­Ø¬Ù… (< 100x100)\")\n",
        "\n",
        "# Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…ÙƒØ±Ø±Ø© Ø¨ØµØ±ÙŠÙ‹Ø§\n",
        "if duplicates:\n",
        "    print(f\"\\nğŸ” Ù…Ø¬Ù…ÙˆØ¹Ø§Øª ØµÙˆØ± Ù…ÙƒØ±Ø±Ø© Ø¨ØµØ±ÙŠÙ‹Ø§: {len(duplicates)}\\n\")\n",
        "    for i, (h, paths) in enumerate(duplicates.items()):\n",
        "        print(f\"\\nğŸ§© Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© {i+1} - Hash: {h} - Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ±: {len(paths)}\")\n",
        "        display_images(paths, f\"ØµÙˆØ± Ù…ÙƒØ±Ø±Ø© - Ù…Ø¬Ù…ÙˆØ¹Ø© {i+1}\")\n",
        "\n",
        "# Ø§Ù„ØµÙˆØ± Ø§Ù„ØªØ§Ù„ÙØ©\n",
        "if bad_images:\n",
        "    display_images(bad_images, \"ØµÙˆØ± ØªØ§Ù„ÙØ©\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsUXCgjobtee"
      },
      "outputs": [],
      "source": [
        "# -------------------------------\n",
        "# Ø­Ø°Ù Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…ÙƒØ±Ø±Ø© (Ù†ØªØ±Ùƒ ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø·)\n",
        "# -------------------------------\n",
        "\n",
        "deleted_count = 0\n",
        "for h, paths in duplicates.items():\n",
        "    # Ù†ØªØ±Ùƒ Ø£ÙˆÙ„ ØµÙˆØ±Ø©ØŒ ÙˆÙ†Ø­Ø°Ù Ø§Ù„Ø¨Ø§Ù‚ÙŠ\n",
        "    for duplicate_path in paths[1:]:\n",
        "        try:\n",
        "            os.remove(duplicate_path)\n",
        "            deleted_count += 1\n",
        "            print(f\"ğŸ—‘ï¸ Ø­Ø°Ù: {duplicate_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ÙØ´Ù„ ÙÙŠ Ø§Ù„Ø­Ø°Ù: {duplicate_path} - {e}\")\n",
        "\n",
        "print(f\"\\nâœ… ØªÙ… Ø­Ø°Ù {deleted_count} ØµÙˆØ±Ø© Ù…ÙƒØ±Ø±Ø© ÙˆØªØ±Ùƒ Ù†Ø³Ø®Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø· Ù…Ù† ÙƒÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø©.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89_PkuyfcPst"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "class_counts = Counter()\n",
        "\n",
        "for root, dirs, files in os.walk(\"/content/Shark_project\"):\n",
        "    for d in dirs:\n",
        "        folder = os.path.join(root, d)\n",
        "        count = len([f for f in os.listdir(folder) if f.lower().endswith(('.jpg', '.png', '.jpeg'))])\n",
        "        class_counts[d] = count\n",
        "\n",
        "print(\"ğŸ“Š ØªÙˆØ²ÙŠØ¹ Ø§Ù„ØµÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„ÙØ¦Ø§Øª:\")\n",
        "for class_name, count in class_counts.items():\n",
        "    print(f\"{class_name:25s}: {count} ØµÙˆØ±Ø©\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91rezNLMeCXn"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "\n",
        "# Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ÙƒÙ„Ø§Ù…Ùƒ\n",
        "base_dir = \"/content/Shark_project/shark_fins_raw\"\n",
        "\n",
        "# Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ØªÙŠ Ù†Ø±ÙŠØ¯ ØªÙˆØ­ÙŠØ¯Ù‡Ø§\n",
        "rename_map = {\n",
        "    \"Bull shark\": \"Bull_Shark\",\n",
        "    \"Mako shark\": \"Mako_Shark\",\n",
        "    \"Tiger_shark\": \"Tiger_Shark\",\n",
        "    \"Great_White_Shark\": \"Great_White_Shark\",\n",
        "    \"Blacktip_Shark\": \"Blacktip_Shark\",\n",
        "    \"Hammerhead_Shark\": \"Hammerhead_Shark\",\n",
        "    \"Whale_Shark\": \"Whale_Shark\",\n",
        "    \"Whitetip_Shark\": \"Whitetip_Shark\",\n",
        "}\n",
        "\n",
        "# ØªÙ†ÙÙŠØ° Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ³Ù…ÙŠØ©\n",
        "for old_name, new_name in rename_map.items():\n",
        "    old_path = os.path.join(base_dir, old_name)\n",
        "    new_path = os.path.join(base_dir, new_name)\n",
        "    if os.path.exists(old_path):\n",
        "        os.rename(old_path, new_path)\n",
        "        print(f\"âœ… Renamed: {old_name} â†’ {new_name}\")\n",
        "    else:\n",
        "        print(f\"âš ï¸ Skipped (not found): {old_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqytharSehIH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import random\n",
        "\n",
        "# Ù…Ø¬Ù„Ø¯ Ø§Ù„ØµÙˆØ±\n",
        "base_dir = \"/content/Shark_project/shark_fins_raw\"\n",
        "\n",
        "# Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£ØµÙ†Ø§Ù\n",
        "shark_classes = sorted([d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))])\n",
        "\n",
        "# Ù„ÙƒÙ„ ØµÙ†ÙØŒ Ù†Ø¹Ø±Ø¶ 3 ØµÙˆØ±\n",
        "for shark_class in shark_classes:\n",
        "    class_path = os.path.join(base_dir, shark_class)\n",
        "    images = [img for img in os.listdir(class_path) if img.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
        "\n",
        "    # Ù„Ùˆ Ù…ÙÙŠØ´ ØµÙˆØ±ØŒ Ù†Ø¹Ø¯ÙŠ\n",
        "    if len(images) == 0:\n",
        "        continue\n",
        "\n",
        "    # Ù†Ø®ØªØ§Ø± 3 ØµÙˆØ± Ø¹Ø´ÙˆØ§Ø¦ÙŠÙ‹Ø§ (Ø£Ùˆ Ø£Ù‚Ù„ Ù„Ùˆ Ø§Ù„Ø¹Ø¯Ø¯ Ù…Ø´ ÙƒØ§ÙÙŠ)\n",
        "    sample_images = random.sample(images, min(3, len(images)))\n",
        "\n",
        "    print(f\"\\nğŸ¦ˆ {shark_class} â€” Showing {len(sample_images)} image(s):\")\n",
        "\n",
        "    # Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    for i, img_name in enumerate(sample_images):\n",
        "        img_path = os.path.join(class_path, img_name)\n",
        "        img = mpimg.imread(img_path)\n",
        "        plt.subplot(1, len(sample_images), i+1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "        plt.title(f\"{shark_class}\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USzS6YNvfB7B",
        "outputId": "b9fe71ef-6818-42ec-a6c6-64a2e5cfc92a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 18.78it/s]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ù„Ù„ØµÙˆØ± Ù‚Ø¨Ù„ Ø§Ù„ØªÙ‚Ø³ÙŠÙ…\n",
        "source_dir = \"/content/Shark_project/shark_fins_raw\"\n",
        "# Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø°ÙŠ Ø³Ù†Ù†Ø´Ø¦ ÙÙŠÙ‡ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ù…Ù‚Ø³Ù…Ø©\n",
        "dest_dir = \"/content/Shark_project_split\"\n",
        "\n",
        "# Ø§Ù„Ù†Ø³Ø¨\n",
        "train_ratio = 0.7\n",
        "val_ratio = 0.15\n",
        "test_ratio = 0.15\n",
        "\n",
        "# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯Ø§Øª train, val, test\n",
        "splits = ['train', 'val', 'test']\n",
        "for split in splits:\n",
        "    split_path = os.path.join(dest_dir, split)\n",
        "    os.makedirs(split_path, exist_ok=True)\n",
        "\n",
        "# Ù„ÙƒÙ„ ØµÙ†Ù Ù†Ù†Ø³Ø® Ø§Ù„ØµÙˆØ± Ø­Ø³Ø¨ Ø§Ù„Ù†Ø³Ø¨Ø©\n",
        "for class_name in tqdm(os.listdir(source_dir)):\n",
        "    class_path = os.path.join(source_dir, class_name)\n",
        "    if not os.path.isdir(class_path):\n",
        "        continue\n",
        "\n",
        "    images = [f for f in os.listdir(class_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "    random.shuffle(images)\n",
        "\n",
        "    n_total = len(images)\n",
        "    n_train = int(train_ratio * n_total)\n",
        "    n_val = int(val_ratio * n_total)\n",
        "\n",
        "    split_counts = {\n",
        "        'train': images[:n_train],\n",
        "        'val': images[n_train:n_train+n_val],\n",
        "        'test': images[n_train+n_val:]\n",
        "    }\n",
        "\n",
        "    for split in splits:\n",
        "        split_class_dir = os.path.join(dest_dir, split, class_name)\n",
        "        os.makedirs(split_class_dir, exist_ok=True)\n",
        "        for img_file in split_counts[split]:\n",
        "            src_path = os.path.join(class_path, img_file)\n",
        "            dst_path = os.path.join(split_class_dir, img_file)\n",
        "            shutil.copy2(src_path, dst_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UJ4s-QnYQDP"
      },
      "outputs": [],
      "source": [
        "!unzip \"/content/sharks_raw.zip \"-d \"/content/Shark_project\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbyI3qi5HPwo",
        "outputId": "af987567-26c2-4a5e-f700-59a8b543afd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=14uDazr8KcJqzV4A52EuQ-gOMoorWEOek\n",
            "From (redirected): https://drive.google.com/uc?id=14uDazr8KcJqzV4A52EuQ-gOMoorWEOek&confirm=t&uuid=0515d6eb-233a-4775-81da-ed0b1109cf1f\n",
            "To: /content/sharks_raw.zip\n",
            "100% 142M/142M [00:01<00:00, 83.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Ù‡Ø°Ø§ Ù‡Ùˆ Ø§Ù„Ù€ File ID Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø·:\n",
        "# https://drive.google.com/file/d/14uDazr8KcJqzV4A52EuQ-gOMoorWEOek/view\n",
        "# ID Ù‡Ùˆ: 14uDazr8KcJqzV4A52EuQ-gOMoorWEOek\n",
        "\n",
        "!gdown 14uDazr8KcJqzV4A52EuQ-gOMoorWEOek"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfBZpYD7a0Px"
      },
      "outputs": [],
      "source": [
        "!unzip \"/content/sharks_raw.zip\" -d \"/content/Shark_project\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyQ8EIf4G-vE"
      },
      "outputs": [],
      "source": [
        "pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4wr88hNhGW_P"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers datasets torchvision evaluate\n",
        "!pip install wandb\n",
        "\n",
        "\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "\n",
        "# Ø§Ù„Ù…Ø³Ø§Ø± Ø¥Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
        "data_dir = \"/content/Shark_project_split\"\n",
        "\n",
        "# Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø¨Ø¯Ø¦ÙŠØ© (ØªØµØºÙŠØ± Ø§Ù„ØµÙˆØ± ÙˆØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ø¥Ù„Ù‰ Tensor)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
        "dataset = ImageFolder(data_dir, transform=transform)\n",
        "\n",
        "# ØªÙ‚Ø³ÙŠÙ… Ø¥Ù„Ù‰ ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ø®ØªØ¨Ø§Ø±\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "\n",
        "#---\n",
        "\n",
        "from transformers import ViTForImageClassification, ViTFeatureExtractor, TrainingArguments, Trainer, ViTImageProcessor\n",
        "import torch\n",
        "import numpy as np\n",
        "from datasets import Dataset as HFDataset\n",
        "\n",
        "# Ø§Ø³ØªØ®Ù„Ø§Øµ Ø§Ù„Ø®ØµØ§Ø¦Øµ\n",
        "# feature_extractor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224\") # Deprecated\n",
        "feature_extractor = ViTImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n",
        "\n",
        "# ØªØ¹Ø±ÙŠÙ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØµÙ†ÙŠÙ\n",
        "model = ViTForImageClassification.from_pretrained(\n",
        "    \"google/vit-base-patch16-224\",\n",
        "    num_labels=len(dataset.classes),\n",
        "    id2label={str(i): c for i, c in enumerate(dataset.classes)},\n",
        "    label2id={c: str(i) for i, c in enumerate(dataset.classes)},\n",
        "    ignore_mismatched_sizes=True # Add this argument to ignore the size mismatch in the classifier layer\n",
        ")\n",
        "\n",
        "#----\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "def transform_example(example):\n",
        "    image = example['image']\n",
        "    encoding = feature_extractor(images=image, return_tensors=\"pt\")\n",
        "    encoding['label'] = example['label']\n",
        "    return encoding\n",
        "\n",
        "# ØªØ­ÙˆÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª PyTorch Ø¥Ù„Ù‰ Dataset Ù…Ù† Ù†ÙˆØ¹ Hugging Face\n",
        "def convert_to_hf_dataset(torch_dataset):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for img, label in torch_dataset:\n",
        "        images.append(img.permute(1, 2, 0).numpy())  # Convert to HWC\n",
        "        labels.append(label)\n",
        "    return HFDataset.from_dict({\"image\": images, \"label\": labels})\n",
        "\n",
        "hf_train = convert_to_hf_dataset(train_dataset).with_transform(transform_example)\n",
        "hf_val = convert_to_hf_dataset(val_dataset).with_transform(transform_example)\n",
        "\n",
        "\n",
        "#----\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./vit-shark-classifier2\",\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    eval_strategy=\"epoch\", # Changed from evaluation_strategy\n",
        "    save_strategy=\"epoch\",\n",
        "    num_train_epochs=5,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "from evaluate import load\n",
        "accuracy = load(\"accuracy\")\n",
        "\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "def compute_metrics(p):\n",
        "    preds = np.argmax(p.predictions, axis=1)\n",
        "    return accuracy.compute(predictions=preds, references=p.label_ids)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=hf_train,\n",
        "    eval_dataset=hf_val,\n",
        "    image_processor=feature_extractor,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84M8J_pAG2N_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "7bef7f6e-21e4-4d3e-a861-aa2835c28440"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-59f0fe5e-cfb2-4e18-86fa-19901dfbad43\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-59f0fe5e-cfb2-4e18-86fa-19901dfbad43\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ù…Ù† Ø§Ù„Ø¬Ù‡Ø§Ø² Ø§Ù„Ù…Ø­Ù„ÙŠ\n",
        "uploaded = files.upload()\n",
        "image_path = list(uploaded.keys())[0]  # Ø£ÙˆÙ„ Ù…Ù„Ù Ù…Ø±ÙÙˆØ¹\n",
        "\n",
        "# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (ØªØ£ÙƒØ¯ Ø¥Ù†Ùƒ Ù…Ø­Ù…Ù„ ÙˆÙ…Ù‡ÙŠØ¦ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ø¨Ø§Ø³Ù… model)\n",
        "model.eval()\n",
        "\n",
        "# ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£ØµÙ†Ø§Ù\n",
        "class_names = [\n",
        "    'Blacktip_Shark', 'Bull_Shark',\n",
        "    'Great_White_Shark', 'Hammerhead_Shark',\n",
        "    'Mako_Shark', 'Tiger_Shark',\n",
        "    'Whale_Shark', 'Whitetip_Shark'\n",
        "]\n",
        "\n",
        "# Ù†ÙØ³ Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© ÙÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨\n",
        "transform = T.Compose([\n",
        "    T.Resize((224, 224)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# ÙØªØ­ Ø§Ù„ØµÙˆØ±Ø©\n",
        "image = Image.open(image_path).convert(\"RGB\")\n",
        "input_tensor = transform(image).unsqueeze(0)\n",
        "\n",
        "# Ø§Ù„ØªÙˆÙ‚Ø¹\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_tensor)\n",
        "    predicted_class = outputs.argmax(dim=1).item()\n",
        "\n",
        "# Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªÙŠØ¬Ø©\n",
        "predicted_label = class_names[predicted_class]\n",
        "print(f\"âœ… Predicted Shark Type: {predicted_label}\")\n",
        "\n",
        "# Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±Ø©\n",
        "plt.imshow(image)\n",
        "plt.title(f\"Prediction: {predicted_label}\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "\n",
        "# ØªÙØ¹ÙŠÙ„ GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØªØ­Ø¯ÙŠØ¯ eval mode\n",
        "model = torch.load(\"/content/model.pt\", map_location=device)\n",
        "model.eval()\n",
        "model.to(device)\n",
        "\n",
        "# Ø§Ù„Ø£ØµÙ†Ø§Ù\n",
        "class_names = [\n",
        "    'Blacktip_Shark', 'Bull_Shark',\n",
        "    'Great_White_Shark', 'Hammerhead_Shark',\n",
        "    'Mako_Shark', 'Tiger_Shark',\n",
        "    'Whale_Shark', 'Whitetip_Shark'\n",
        "]\n",
        "\n",
        "# Ø§Ù„ØªØ­ÙˆÙŠÙ„\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Ø±ÙØ¹ Ø§Ù„ØµÙˆØ±Ø©\n",
        "uploaded = files.upload()\n",
        "image_path = list(uploaded.keys())[0]\n",
        "image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "# Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©\n",
        "input_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "# Ø§Ù„ØªÙ†Ø¨Ø¤\n",
        "with torch.no_grad():\n",
        "    output = model(input_tensor)\n",
        "    pred_idx = output.argmax(1).item()\n",
        "    label = class_names[pred_idx]\n",
        "\n",
        "# Ø¹Ø±Ø¶\n",
        "print(\"âœ… Ù†ÙˆØ¹ Ø§Ù„Ù‚Ø±Ø´:\", label)\n",
        "plt.imshow(image)\n",
        "plt.title(f\"Prediction: {label}\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jrz9ptHgYYb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = ImageFolder(\"/content/Shark_project_split/train\")\n",
        "print(dataset.classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgYmD4TlT5Nx",
        "outputId": "b1a7f2d3-5391-492d-df9a-ffbd62782c75"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Blacktip_Shark', 'Bull_Shark', 'Great_White_Shark', 'Hammerhead_Shark', 'Mako_Shark', 'Tiger_Shark', 'Whale_Shark', 'Whitetip_Shark']\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMNcfB4cjYRGKDrTx5qUq+5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}