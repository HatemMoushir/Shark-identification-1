{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2cEwCcTT+oAsunwLZVdt1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HatemMoushir/Shark-identification-1/blob/main/Shark%20identification_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zMDwjhnXEMwL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67e9a6eb-6dd8-4972-ed35-bdf43ae69d22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15t79wl8laOraKSqZ98ZD2bLOALIFRdtm\n",
            "To: /content/model_complete.pt\n",
            "100% 44.8M/44.8M [00:01<00:00, 37.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# upload model_complete.pt\n",
        "!gdown 15t79wl8laOraKSqZ98ZD2bLOALIFRdtm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# upload deepsharkid_model.pt\n",
        "!gdown 15idmDHaNf9uB0cFC1xHkhV0cY2EmKzjh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cLDybgOmAHF",
        "outputId": "622f4b7b-7d1b-4805-d84c-a4e74ae87f9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15idmDHaNf9uB0cFC1xHkhV0cY2EmKzjh\n",
            "To: /content/deepsharkid_model.pt\n",
            "100% 44.8M/44.8M [00:01<00:00, 36.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#https://drive.google.com/file/d/1zYO65EqTews34z3f7c6qBAy2eRTeC0Q0/view?usp=drivesdk\n",
        "# upload test5.jpg\n",
        "!gdown 1zYO65EqTews34z3f7c6qBAy2eRTeC0Q0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlLH7z2Z_k0v",
        "outputId": "ddfeeb27-cd57-4ffe-9382-81dac33407a5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1zYO65EqTews34z3f7c6qBAy2eRTeC0Q0\n",
            "To: /content/Test5.jpg\n",
            "\r  0% 0.00/710k [00:00<?, ?B/s]\r100% 710k/710k [00:00<00:00, 29.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# upload test77.jpg\n",
        "!gdown 1AcM4gv0Hfum21o0LsrwHTWYeKmUkxuUb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_rfrFUIC-08",
        "outputId": "83f4b556-e39c-4d63-d7e3-8f27b6a522da"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1AcM4gv0Hfum21o0LsrwHTWYeKmUkxuUb\n",
            "To: /content/Test77.jpg\n",
            "\r  0% 0.00/99.9k [00:00<?, ?B/s]\r100% 99.9k/99.9k [00:00<00:00, 72.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1O1TTMFQmXziQ4_78-asNBbEhkPEJcDzt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiE_CvkoDzr_",
        "outputId": "e0430cae-7593-426f-b09f-9ff9a8447b18"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1O1TTMFQmXziQ4_78-asNBbEhkPEJcDzt\n",
            "To: /content/test29.jpg\n",
            "\r  0% 0.00/674k [00:00<?, ?B/s]\r100% 674k/674k [00:00<00:00, 39.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from transformers import ViTForImageClassification\n",
        "\n",
        "model = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224\")\n",
        "model.load_state_dict(torch.load(\"/content/deepsharkid_model.pt\"))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "nMc3xmp7SYn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obj = torch.load(\"/content/deepsharkid_model.pt\")\n",
        "print(type(obj))"
      ],
      "metadata": {
        "id": "PZ6MX43ywEH3",
        "outputId": "989c3f88-a16b-431e-ceac-64d81dad52ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'collections.OrderedDict'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import resnet18\n",
        "import torch\n",
        "\n",
        "model = resnet18()\n",
        "model.load_state_dict(torch.load(\"/content/deepsharkid_model.pt\"))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "VClrw71nx0d2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "state = torch.load(\"/content/deepsharkid_model.pt\")\n",
        "print(type(state))\n",
        "if isinstance(state, dict):\n",
        "    print(list(state.keys())[:10])  # أول 10 مفاتيح"
      ],
      "metadata": {
        "id": "wqc8Ian7y1D8",
        "outputId": "c2d6b286-e28a-41bc-bf3e-93b7b119b3bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'collections.OrderedDict'>\n",
            "['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# احمل النموذج كاملًا مع تجاوز الحماية الجديدة (لو واثق في الملف)\n",
        "model = torch.load(\"/content/model_complete.pt\", weights_only=False)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOq_W5EozoqV",
        "outputId": "b1c0c89e-8b4e-4a12-ee23-6a423399526e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=9, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "\n",
        "# تحميل النموذج\n",
        "print(\"[1] تحميل النموذج...\")\n",
        "model = torch.load(\"/content/model_complete.pt\", weights_only=False)\n",
        "model.eval()\n",
        "print(\"[2] النموذج جاهز!\")\n",
        "\n",
        "# تحميل الصورة من الجهاز\n",
        "#####print(\"[3] الرجاء اختيار الصورة من جهازك...\")\n",
        "#####uploaded = files.upload()\n",
        "\n",
        "# الحصول على اسم الملف\n",
        "######image_path = next(iter(uploaded))\n",
        "image_path  =\"/content/test29.jpg\"\n",
        "print(f\"[4] تم تحميل الصورة: {image_path}\")\n",
        "\n",
        "# فتح الصورة\n",
        "img = Image.open(image_path).convert(\"RGB\")\n",
        "print(\"[5] تم فتح الصورة!\")\n",
        "\n",
        "# التحويلات (حسب ما تدرب عليه النموذج)\n",
        "transform = T.Compose([\n",
        "    T.Resize((224, 224)),  # غيّر لو نموذجك مدرب على مقاسات تانية\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# تجهيز الصورة للنموذج\n",
        "print(\"[6] تحويل الصورة إلى تنسور...\")\n",
        "input_tensor = transform(img).unsqueeze(0)\n",
        "print(f\"[7] شكل التنسور: {input_tensor.shape}\")\n",
        "\n",
        "# توقع النوع\n",
        "print(\"[8] تنفيذ التنبؤ...\")\n",
        "with torch.no_grad():\n",
        "    output = model(input_tensor)\n",
        "    predicted_class = output.argmax(dim=1).item()\n",
        "print(f\"[9] الكلاس المتوقع: {predicted_class}\")\n",
        "\n",
        "class_names = [\n",
        "    'Blacktip_Shark',\n",
        "    'Bull_Shark',\n",
        "    'Great_White_Shark',\n",
        "    'Hammerhead_Shark',\n",
        "    'Mako_Shark',\n",
        "    'Tiger_Shark',\n",
        "    'Whale_Shark',\n",
        "    'Whitetip_Shark'\n",
        "]\n",
        "\n",
        "predicted_label = class_names[predicted_class]\n",
        "print(f\"[9] الكلاس المتوقع: {predicted_class}\")\n",
        "print(f\"[10] اسم النوع المتوقع: {predicted_label}\")\n",
        "\n",
        "# print(f\"[10] الاسم المتوقع: {class_names[predicted_class]}\")\n",
        "\n",
        "\n",
        "print(\"[8] تنفيذ التنبؤ...\")\n",
        "with torch.no_grad():\n",
        "    output = model(img_tensor)\n",
        "    print(\"[8.1] شكل الـ output:\", output.shape)\n",
        "\n",
        "    probs = torch.nn.functional.softmax(output[0], dim=0)\n",
        "    predicted_class = torch.argmax(probs).item()\n",
        "\n",
        "    print(\"[9] الكلاس المتوقع:\", predicted_class)\n",
        "    print(\"[10] اسم النوع المتوقع:\", class_names[predicted_class])\n",
        "    print(\"[11] نسب التنبؤ لكل نوع:\")\n",
        "    for idx, (cls_name, prob) in enumerate(zip(class_names, probs)):\n",
        "        print(f\"    {idx}: {cls_name:25s} -> {prob:.4f}\")"
      ],
      "metadata": {
        "id": "9mLJ_U9l7KW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "339wbgdXFdIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# تحميل النموذج المدرب\n",
        "print(\"[1] تحميل النموذج...\")\n",
        "model = torch.load(\"/content/model.pth\", map_location=torch.device('cpu'))\n",
        "model.eval()\n",
        "print(\"[2] النموذج جاهز!\")\n",
        "\n",
        "# أسماء الأنواع\n",
        "class_names = [\n",
        "    \"Blacktip_Shark\", \"Bull_Shark\", \"Great_White_Shark\", \"Hammerhead_Shark\",\n",
        "    \"Mako_Shark\", \"Tiger_Shark\", \"Whale_Shark\", \"Whitetip_Shark\", \"Thresher_Shark\"\n",
        "]\n",
        "\n",
        "# تحميل الصورة\n",
        "img_path = \"/content/test29.jpg\"\n",
        "print(\"[4] تم تحميل الصورة:\", img_path)\n",
        "img = Image.open(img_path).convert(\"RGB\")\n",
        "print(\"[5] تم فتح الصورة!\")\n",
        "\n",
        "# تحويل الصورة لتنسور\n",
        "transform = T.Compose([\n",
        "    T.Resize((224, 224)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "img_tensor = transform(img).unsqueeze(0)  # إضافة batch dimension\n",
        "print(\"[6] تحويل الصورة إلى تنسور...\")\n",
        "print(\"[7] شكل التنسور:\", img_tensor.shape)\n",
        "\n",
        "# تنفيذ التنبؤ\n",
        "print(\"[8] تنفيذ التنبؤ...\")\n",
        "with torch.no_grad():\n",
        "    output = model(img_tensor)\n",
        "    print(\"[8.1] شكل الـ output:\", output.shape)\n",
        "\n",
        "    probs = torch.nn.functional.softmax(output[0], dim=0)\n",
        "    predicted_class = torch.argmax(probs).item()\n",
        "\n",
        "    print(\"[9] الكلاس المتوقع:\", predicted_class)\n",
        "    print(\"[10] اسم النوع المتوقع:\", class_names[predicted_class])\n",
        "    print(\"[11] نسب التنبؤ لكل نوع:\")\n",
        "    for idx, (cls_name, prob) in enumerate(zip(class_names, probs)):\n",
        "        print(f\"    {idx}: {cls_name:25s} -> {prob:.4f}\")\n",
        "\n",
        "# عرض الصورة والنتيجة\n",
        "plt.imshow(img)\n",
        "plt.title(f\"Predicted: {class_names[predicted_class]}\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "gm578jOe9m1S",
        "outputId": "f5439583-ab18-4daf-acb5-a3a76b17edec"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] تحميل النموذج...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/model.pth'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-20-290490968.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# تحميل النموذج المدرب\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[1] تحميل النموذج...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/model.pth\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[2] النموذج جاهز!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1425\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/model.pth'"
          ]
        }
      ]
    }
  ]
}